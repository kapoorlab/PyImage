{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aimachine/anaconda3/envs/tensorflowpy3pt5/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/aimachine/anaconda3/envs/tensorflowpy3pt5/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/aimachine/anaconda3/envs/tensorflowpy3pt5/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/aimachine/anaconda3/envs/tensorflowpy3pt5/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/aimachine/anaconda3/envs/tensorflowpy3pt5/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/Users/aimachine/PyImage/utils\")\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import skimage\n",
    "import cv2\n",
    "import time\n",
    "from skimage import measure\n",
    "from skimage import filters\n",
    "from sklearn.cluster import DBSCAN\n",
    "from skimage.filters import threshold_otsu\n",
    "from tifffile import imread\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from skimage.filters.rank import median\n",
    "from scipy import ndimage\n",
    "from scipy.ndimage.filters import median_filter\n",
    "from DBScan import segment_dbscan,show_clusters_DBSCAN\n",
    "from DiscreteClustering import Discretize_Clustering\n",
    "from Normalize import normalizeFloat, normalizeMinMax, Path, save_tiff_imagej_compatible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = '/Users/aimachine/Documents/JuliaData/Julia/Subset/OzRawMedian/Boundary/'\n",
    "targetdir = '/Users/aimachine/Documents/JuliaData/Julia/Subset/OzRawMedian/Result/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of input images =  1\n",
      "Image size =  (241, 321, 314)\n",
      "Time dim =  241\n"
     ]
    }
   ],
   "source": [
    "Path = os.path.join(basedir, '*.tif')\n",
    "X = []\n",
    "Names = []\n",
    "filesRaw = glob.glob(Path)\n",
    "maxtime = 0\n",
    "axes = 'TYX'\n",
    "for fname in filesRaw:\n",
    "      x = imread(fname)\n",
    "      min = 0\n",
    "      max = 255\n",
    "      x = normalizeMinMax(x, min, max)  \n",
    "      \n",
    "      X.append(x)\n",
    "    \n",
    "     \n",
    "      Names.append(fname)\n",
    "      if X[0].shape[0] > maxtime:\n",
    "        maxtime = X[0].shape[0]\n",
    "X.sort\n",
    "Names.sort\n",
    "\n",
    "\n",
    "ReshapeX = []\n",
    "for i in range(len(X)):\n",
    "    y = np.zeros((maxtime, X[0].shape[1], X[0].shape[2]))\n",
    "    image = X[i]\n",
    "    \n",
    "    y[:X[i].shape[0],:,:] = image[:,:,:]\n",
    "    ReshapeX.append(y)\n",
    "    \n",
    "ReshapeX.sort\n",
    "\n",
    "print('Total number of input images = ', len(X))\n",
    "print('Image size = ', X[0].shape)\n",
    "print('Time dim = ', maxtime)\n",
    "\n",
    "timerange = maxtime\n",
    "\n",
    "doDBscan = True\n",
    "doClustering = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Clustering(img):\n",
    "    Labels = img\n",
    "    T_REGIONS = []\n",
    "    for j in range(timerange):\n",
    "      smallimg = img[j,:,:]\n",
    "      \n",
    "      \"\"\"Put clustering code\"\"\"\n",
    "      \n",
    "      labels, N_REGIONS =Discretize_Clustering(smallimg, N_REGIONS = 150)\n",
    "      Labels[j,:,:] = labels\n",
    "      T_REGIONS.append( N_REGIONS)  \n",
    "    return Labels, T_REGIONS       \n",
    "\n",
    "    \n",
    "       \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DBScan(img):\n",
    "    \n",
    "    \n",
    "    \n",
    "    segmentation_params = {\n",
    "        \"IntensityThreshold\": 45,\n",
    "        \"BlurKernelSize\": 3,\n",
    "        \"BlurSigma\": 1,\n",
    "\n",
    "        \"Clustering\": {\n",
    "            \"Eps\": 2,\n",
    "            \"MinDensity\": 70,\n",
    "            \"BorderPoints\": 1,\n",
    "\n",
    "            \"KdTree\": {\n",
    "                \"BucketSize\": 20,\n",
    "                \"SplitRule\": 4,\n",
    "                \"Approx\": 0\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "    Labels = img\n",
    "    Clusters = []\n",
    "    for j in range(timerange):\n",
    "      smallimg = img[j,:,:]\n",
    "      \n",
    "      #medianimg = median_filter(smallimg, size = 2)\n",
    "      cluster_list, cluster_image = segment_dbscan(smallimg, segmentation_params)\n",
    "      Labels[j,:,:] = cluster_image;  \n",
    "      Clusters.append(cluster_list)\n",
    "    return Labels, Clusters     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (0) into shape (321,314)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-42db3fc5d4aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdoDBscan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mLabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mClusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDBScan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time taken'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-faf72f426431>\u001b[0m in \u001b[0;36mDBScan\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     27\u001b[0m       \u001b[0;31m#medianimg = median_filter(smallimg, size = 2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0mcluster_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegment_dbscan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmallimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegmentation_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m       \u001b[0mLabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster_image\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m       \u001b[0mClusters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mLabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mClusters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (0) into shape (321,314)"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(ReshapeX)):\n",
    "  newimg = ReshapeX[i]\n",
    "  Clusterimg = newimg;\n",
    "  t0 = time.time()\n",
    "  if doDBscan:\n",
    "    Labels, Clusters = DBScan(newimg)\n",
    "    t1 = time.time()\n",
    "    print('time taken', t1 - t0)\n",
    "    save_tiff_imagej_compatible((targetdir + 'SuperPixel' + os.path.basename(Names[i])) , Labels, axes)\n",
    "    \n",
    "    \n",
    "  if doClustering:\n",
    "    Labels, T_REGIONS = Clustering(newimg)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenumber = 0;\n",
    "if imagenumber > maxtime:\n",
    "   imagenumber = maxtime - 1\n",
    "if doDBscan:\n",
    "    plt.figure(1)\n",
    "    \n",
    "    label = Labels[0]\n",
    "    img = newimg[0,:,:]\n",
    "    labelimg = label[:,:]    \n",
    "    clusterimg = show_clusters_DBSCAN(img, Clusters[0])\n",
    "    \n",
    "    plt.imshow(labelimg)\n",
    "    plt.show() \n",
    "if doClustering:\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(newimg[0,:,:])\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(newimg[0,:,:])\n",
    "    N_REGIONS = T_REGIONS[0]\n",
    "    labels = Labels[0,:,:]\n",
    "    for l in range(N_REGIONS):\n",
    "        \n",
    "        plt.contour(labels == l, contours=1,\n",
    "                    colors=[plt.cm.nipy_spectral(l / float(N_REGIONS)), ])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflowpy3pt5]",
   "language": "python",
   "name": "conda-env-tensorflowpy3pt5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HelloWo.. [CIFAR10](https://keras.io/datasets/)!\n",
    "\n",
    "In this notebook, we will explore convolutional neural networks.\n",
    "\n",
    "First, we load numpy and matplotlib as well as the keras layers we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sw/apps/python3/3.6.5/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/sw/apps/python3/3.6.5/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# numpy and plotting\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# keras\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Softmax\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Load CIFAR10 dataset **\n",
    "\n",
    "We load the CIFAR10 dataset provided by keras, it contains 32x32-pixel images from ten classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras import backend as K\n",
    "\n",
    "# The data, shuffled and split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "# maximum value normalization\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "num_classes = 10\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, we set reshape the dataset to have the color channels in the place the backend require. Tensorflow requires \"channels_last\".\n",
    "\n",
    "We also convert the labels to one-hot-encoded labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 10)\n",
      "(10000, 32, 32, 3)\n",
      "(10000, 10)\n",
      "channels_last\n",
      "(32, 32, 3)\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Convert class vectors to binary class matrices.\n",
    "#y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "#y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "img_rows, img_cols, channels = x_train.shape[1:]\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], channels, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], channels, img_rows, img_cols)\n",
    "    input_shape = (channels, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, channels)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, channels)\n",
    "    input_shape = (img_rows, img_cols, channels)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(K.image_data_format())\n",
    "print(input_shape)\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictCategorical(idx, model, data, preproc= None, cols=5):\n",
    "    try:\n",
    "        idx = list(idx)\n",
    "    except:\n",
    "        idx = [idx]\n",
    "        \n",
    "    data = data[idx]\n",
    "        \n",
    "    p = model.predict(data if preproc is None else preproc(data))\n",
    "    \n",
    "    ncats = 0\n",
    "    ndogs = 0\n",
    "    nother = 0\n",
    "    \n",
    "    i=0\n",
    "    labels = [\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]\n",
    "    while i < p.shape[0]:\n",
    "        fig, axs = plt.subplots(1,cols,figsize=(5*cols,5))\n",
    "        fig.figsize=(20,10)\n",
    "        for ax in axs:\n",
    "            ax.imshow(data[i])\n",
    "            label = np.argsort(p[i])[-1]\n",
    "            ax.text(.5,0, labels[label]+\", score \"+str(p[i][label]),\n",
    "                    horizontalalignment='center', verticalalignment='bottom', transform=ax.axes.transAxes,\n",
    "                    backgroundcolor=\"white\", size=\"large\")\n",
    "            i += 1\n",
    "            if i >= p.shape[0]:\n",
    "                break\n",
    "            \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: Multi-Layer Perceptron (MLP)\n",
    "\n",
    "To get a baseline, we try a multi-layer perceptron: A model with a few hidden dense layers. If there are enough of those (>~3), the model can be considered deep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeMLP(hidden = [512,512,256], activation = 'relu', input_shape=input_shape, num_classes=num_classes):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # converts the images (32x32x3) into vectors\n",
    "    model.add(Flatten(input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    for a in hidden:\n",
    "        model.add(Dense(a, activation=activation))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 3072)              12288     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 1,982,218\n",
      "Trainable params: 1,976,074\n",
      "Non-trainable params: 6,144\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = makeMLP()\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, that this small MLP with three hidden layers of sizes 512, 512 and 256, already has about 2 million trainable parameters. The size of 512 activations is also not unreasonably large, as this already leads to a dimensional reduction of the input by a factor of 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 1.7315 - acc: 0.3929 - val_loss: 1.5469 - val_acc: 0.4495\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.4731 - acc: 0.4795 - val_loss: 1.4705 - val_acc: 0.4854\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.3462 - acc: 0.5233 - val_loss: 1.4499 - val_acc: 0.4978\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2343 - acc: 0.5642 - val_loss: 1.3614 - val_acc: 0.5223\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.1394 - acc: 0.5960 - val_loss: 1.3831 - val_acc: 0.5260\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.0576 - acc: 0.6232 - val_loss: 1.4500 - val_acc: 0.5194\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.9696 - acc: 0.6550 - val_loss: 1.4196 - val_acc: 0.5299\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.8816 - acc: 0.6866 - val_loss: 1.4362 - val_acc: 0.5432\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.8025 - acc: 0.7135 - val_loss: 1.4911 - val_acc: 0.5388\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.7352 - acc: 0.7388 - val_loss: 1.6434 - val_acc: 0.5201\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.6558 - acc: 0.7648 - val_loss: 1.6874 - val_acc: 0.5387\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.5934 - acc: 0.7881 - val_loss: 1.8133 - val_acc: 0.5327\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.5276 - acc: 0.8135 - val_loss: 1.8872 - val_acc: 0.5244\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.4773 - acc: 0.8289 - val_loss: 1.9772 - val_acc: 0.5343\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.4260 - acc: 0.8490 - val_loss: 2.0120 - val_acc: 0.5380\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.3823 - acc: 0.8642 - val_loss: 2.3730 - val_acc: 0.5372\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.3479 - acc: 0.8785 - val_loss: 2.3401 - val_acc: 0.5216\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.3149 - acc: 0.8894 - val_loss: 2.4078 - val_acc: 0.5380\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 0.2888 - acc: 0.8997 - val_loss: 2.4292 - val_acc: 0.5323\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 0.2646 - acc: 0.9092 - val_loss: 2.5910 - val_acc: 0.5443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9bd4bb4208>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=20,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can note down, that the validation accuray maxes out at about 53%. This is not nothing, as with ten classed, pure guessing would give an accuracy of 10%.\n",
    "\n",
    "It also starts overfitting quite quickly. This could be mitigated by using data augmentation and more regularization to an extent, which could also inprove the generalization somewhat. But we want to focus on the comparison with convnets here and thus will keep the other aspects simple. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network\n",
    "\n",
    "Let us no go to a very simple CNN. We compared to the previous MLP, we only replace the two larger hidden layers near the bottom by downsampling conv-layers. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCNN1(filters = (32, 64), dense = (256,), kernel_size=(3,3), activation='relu'\n",
    "            , input_shape=input_shape, num_classes=num_classes, normAfterConv=False):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # using input layer to set input size explicitly, before we loop over layers\n",
    "    model.add(BatchNormalization(input_shape=input_shape))\n",
    "    \n",
    "    for a in filters:\n",
    "        \n",
    "        model.add(Conv2D(a, kernel_size=kernel_size, activation=activation, strides=(2,2)))\n",
    "        if normAfterConv:\n",
    "            model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    for a in dense:\n",
    "        model.add(Dense(a, activation=activation))\n",
    "    \n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "       \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "64\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_7 (Batch (None, 32, 32, 3)         12        \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 15, 15, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 514       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                30        \n",
      "=================================================================\n",
      "Total params: 823,020\n",
      "Trainable params: 823,014\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = makeCNN1()\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concept of having conv layers 'looking' at the data and dense layers at the bottom interpreting the features found by the convolutional filters, has been used by early ImageNet-winning deep conv-nets.\n",
    "\n",
    "Note, that this model only has ~825k trainable parameters, of which more than 800k are in the bottom dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=10,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model already reaches a validation accuracy of ~65%, about 10% more than our MLP. It seems to be even more prone to overfitting, however. This could be improved by adding more regularization.\n",
    "\n",
    "### Pure Convnet\n",
    "\n",
    "Let us try an (almost) pure convnet next. Basically, we eliminate the hidden dense layers completely and only retain the dens output layer, which uses the feature map generated by the conv layers and produces the prediction. We add more conv layers to improve the models abstraction ability and to produce a smaller featuremap at the bottom, which controls the input size of the final dense layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = makeCNN1((32,64,96,96),[], normAfterConv=True)\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=10,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This mode is only marginally better, but note, that now we only need ~169k parameters to get the same result.\n",
    "\n",
    "### Small Darknet\n",
    "\n",
    "The previous CNNs took some inspiration from an architecture called darknet, which is used in the YOLO approach to object detection [https://pjreddie.com/darknet/yolo/] .\n",
    "\n",
    "The inspired part is increasing the number of filters after downsamling, but there is more to the to that architecture. So let us try this correctly, but smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeSmallDarknet(nunits=3, nfilters0=16, kernel_size=(3,3), activation='relu'\n",
    "                     , input_shape=input_shape, num_classes=num_classes):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(nfilters0, kernel_size=kernel_size, activation=activation\n",
    "                     , input_shape=input_shape, padding=\"same\"))\n",
    "    \n",
    "    for a in range(1,nunits+1):\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(BatchNormalization())\n",
    "        nfilters = int(nfilters0*(2**a))\n",
    "        for s in range(a//2):\n",
    "            model.add(Conv2D(nfilters, kernel_size=kernel_size, activation=activation, padding=\"same\"))\n",
    "            model.add(Conv2D(nfilters//2, kernel_size=(1,1), activation=activation))\n",
    "        model.add(Conv2D(nfilters, kernel_size=kernel_size, activation=activation, padding=\"same\"))\n",
    "        \n",
    "    model.add(Conv2D(num_classes, kernel_size=(1,1), activation=activation))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Softmax())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = makeSmallDarknet()\n",
    "model.summary()\n",
    "\n",
    "opt = keras.optimizers.adam(lr=0.0001, decay=1e-6)\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              #optimizer=opt,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=10,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model can us ~70% in validation accuracy, but since we are not augmenting the data here it also starts to overfit quickly.\n",
    "\n",
    "Using data augmentation, it can reach >80%, but this takes a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "train_generator = train_datagen.flow(x_train, y_train,\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=50000 // batch_size,\n",
    "        epochs=50,\n",
    "        validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"darknet.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting and displaying the feature map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeSmallDarknetFkt(nunits=3, nfilters0=16, kernel_size=(3,3), activation='relu'\n",
    "                     , input_shape=input_shape, num_classes=num_classes):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(nfilters0, kernel_size=kernel_size, activation=activation\n",
    "                     , input_shape=input_shape, padding=\"same\"))\n",
    "    \n",
    "    for a in range(1,nunits+1):\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(BatchNormalization())\n",
    "        nfilters = int(nfilters0*(2**a))\n",
    "        for s in range(a//2):\n",
    "            model.add(Conv2D(nfilters, kernel_size=kernel_size, activation=activation, padding=\"same\"))\n",
    "            model.add(Conv2D(nfilters//2, kernel_size=(1,1), activation=activation))\n",
    "        model.add(Conv2D(nfilters, kernel_size=kernel_size, activation=activation, padding=\"same\"))\n",
    "    \n",
    "    model.add(Conv2D(num_classes, kernel_size=(1,1), activation=activation))\n",
    "    modelTop = Sequential()\n",
    "    modelTop.add(GlobalAveragePooling2D(input_shape=model.output_shape[1:]))\n",
    "    modelTop.add(Softmax())\n",
    "    \n",
    "    modelFull = Model(inputs=model.input, \n",
    "              outputs=modelTop(model.output))\n",
    "    \n",
    "    return modelFull, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelF, modelM = makeSmallDarknetFkt()\n",
    "modelF.summary()\n",
    "\n",
    "opt = keras.optimizers.adam(lr=0.01, decay=1e-6)\n",
    "\n",
    "modelF.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              #optimizer=opt,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = modelF.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=50000 // batch_size,\n",
    "        epochs=10,\n",
    "        validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelF.load_weights(\"darknet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showMaps(idx, model, data, preproc= None, cols=5):\n",
    "    try:\n",
    "        idx = list(idx)\n",
    "    except:\n",
    "        idx = [idx]\n",
    "        \n",
    "    data = data[idx]\n",
    "        \n",
    "    p = model[0].predict(data if preproc is None else preproc(data))\n",
    "    m = model[1].predict(data if preproc is None else preproc(data))\n",
    "    m = np.argmax(m, axis=3)\n",
    "    print(m.shape)\n",
    "    \n",
    "    ncats = 0\n",
    "    ndogs = 0\n",
    "    nother = 0\n",
    "    \n",
    "    i=0\n",
    "    labels = [\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]\n",
    "    while i < p.shape[0]:\n",
    "        fig, axs = plt.subplots(2,cols,figsize=(5*cols,5))\n",
    "        fig.figsize=(20,10)\n",
    "        for ax, axM in zip(axs[0], axs[1]):\n",
    "            ax.imshow(data[i])\n",
    "            axM.imshow(m[i],vmin=0, vmax=len(labels)-1, interpolation=\"none\")\n",
    "            label = np.argsort(p[i])[-1]\n",
    "            ax.text(.5,0, labels[label]+\", score \"+str(p[i][label]),\n",
    "                    horizontalalignment='center', verticalalignment='bottom', transform=ax.axes.transAxes,\n",
    "                    backgroundcolor=\"white\", size=\"large\")\n",
    "            i += 1\n",
    "            if i >= p.shape[0]:\n",
    "                break\n",
    "            \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showMaps(range(20), (modelF,modelM), x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
